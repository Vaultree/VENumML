{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encrypted Logistic Regression\n",
    "\n",
    "In this demo, we are comparing the sklearn library with our own VenumML library enabled by the Vaultree FHE python library, VENumpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plaintext Logistic Regression with Scikit-Learn\n",
    "\n",
    "The below code demonstrates a basic implementation of Logistic Regression using Scikit-Learn for binary classification. Logistic Regression is a statistical model that predicts the probability of a binary outcome (0 or 1) based on a set of features.\n",
    "\n",
    "Here's a breakdown of the steps involved:\n",
    "\n",
    "1. **Data Generation:**\n",
    "    - We use `sklearn.datasets.make_regression` to generate sample data with 10 samples, 2 features, and a small amount of noise.\n",
    "\n",
    "2. **Data Preprocessing:**\n",
    "    - The generated data represents continuous values. For logistic regression, we typically want the target variable to be binary (0 or 1).\n",
    "    - We binarize the target variable `y` using a threshold (set to 4 in this example). Values above the threshold are converted to 1, and values below are converted to 0.\n",
    "    - This process creates a binary classification problem where the model predicts the probability of a sample belonging to the class labeled 1.\n",
    "    - The threshold value can be adjusted based on your specific problem.\n",
    "\n",
    "3. **Train-Test Split:**\n",
    "    - We split the data into training and testing sets using `sklearn.model_selection.train_test_split`.\n",
    "    - The training set is used to train the model, and the testing set is used to evaluate its performance on unseen data.\n",
    "\n",
    "4. **Model Training:**\n",
    "    - We create a Logistic Regression model instance from `sklearn.linear_model.LogisticRegression`.\n",
    "    - The `solver` parameter is set to 'liblinear' which is a suitable choice for smaller datasets.\n",
    "\n",
    "5. **Model Fitting:**\n",
    "    - We call the `fit` method on the model, passing the training data (X_train and y_train_binary) to train the model.\n",
    "\n",
    "6. **Prediction:**\n",
    "    - We use the trained model to make predictions on the testing data (X_test) using the `predict` method. This results in an array of predicted binary labels (0 or 1).\n",
    "\n",
    "7. **Evaluation (not shown in this example):**\n",
    "    - Typically, we would use metrics like accuracy, precision, recall, or F1-score to evaluate the model's performance on the testing set. This step is not included in this basic example.\n",
    "\n",
    "The following code block implements these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generate Sample Data\n",
    "X, y = make_regression(n_samples=100, n_features=2, noise=0.1)\n",
    "\n",
    "# Binarize the target variable (consider adjusting the threshold)\n",
    "threshold = 4\n",
    "y_binary = np.where(y > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-Learn Predictions: [0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train_binary, y_test_binary = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Scikit-Learn LogisticRegression\n",
    "sk_lr = LogisticRegression(solver='liblinear')\n",
    "sk_lr.fit(X_train, y_train_binary)\n",
    "\n",
    "# Make Predictions on Test Set\n",
    "sk_lr_predictions = sk_lr.predict(X_test)\n",
    "\n",
    "# %timeit sk_lr_predictions\n",
    "print(\"Scikit-Learn Predictions:\", sk_lr_predictions)\n",
    "# X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encrypted Logistic Regression with VenumMLlib\n",
    "\n",
    "This code demonstrates training and using an encrypted Logistic Regression model from our VenumMLlib library.\n",
    "\n",
    "1. **Venumpy Context and Security:**\n",
    "   - A `venumpy.SecretContext` object (`ctx`) is created, specifying a security level (128 bits in this example). This context manages the encryption process.\n",
    "\n",
    "2. **Encrypted Logistic Regression Model:**\n",
    "   - The `EncryptedLogisticRegression` class, imported from `venumMLlib.linear_models.regression.logistic_regression`, handles training and prediction with encrypted data representations. It ensures model parameters and data privacy during training and inference.\n",
    "\n",
    "3. **Model Training:**\n",
    "   - An instance of `EncryptedLogisticRegression` is created, passing the `ctx` object to establish the encryption context.\n",
    "   - The `fit` method trains the model using encrypted data representations. Similar to the non-encrypted case, it iteratively updates the model's coefficients to minimize the loss function.\n",
    "Encryption and Prediction:\n",
    "\n",
    "   - **Note:** Due to the stochastic nature of Stochastic Gradient Descent (SGD), even with encrypted logistic regression, there might be slight variations in the decision boundaries between different model runs. This is because SGD updates the model's coefficients based on randomly chosen mini-batches of data.\n",
    "\n",
    "4. **Encryption and Prediction:**\n",
    "   - After training, `my_lr.encrypt_coefficients(ctx)` encrypts the model's coefficients, ensuring they are not stored or revealed in plain text.\n",
    "   - The testing data `X_test` is encrypted using `encrypt_array` from `venum_tools` before making predictions. This protects the raw data from unauthorized access.\n",
    "\n",
    "5. **Encrypted Predictions and Decryption:**\n",
    "\n",
    "   - The predict method is called on the model with the encrypted testing data `(cipher_X)`. The predictions themselves are also encrypted.\n",
    "   - `decrypt_array` from `venum_tools` is used to decrypt the model's predictions, allowing you to work with the results in plain text.\n",
    "\n",
    "6. **Output:**\n",
    "   - The code snippet shows printing the decrypted predictions before applying a threshold. This is an intermediate step before converting the probabilities to class labels.(0 or 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from venumML.venumpy import small_glwe as vp\n",
    "from venumML.venum_tools import decrypt_array\n",
    "\n",
    "# Create venumpy context with 128 bits of security\n",
    "ctx = vp.SecretContext()\n",
    "ctx.precision = 6\n",
    "\n",
    "from venumML.linear_models.regression.logistic_regression import EncryptedLogisticRegression\n",
    "from venumML.venum_tools import encrypt_array\n",
    "\n",
    "# Train EncryptedLogisticRegression Model\n",
    "my_lr = EncryptedLogisticRegression(ctx)\n",
    "my_lr.fit(X_train, y_train_binary)\n",
    "\n",
    "# Decrypt and Evaluate Predictions\n",
    "my_lr.encrypt_coefficients(ctx)  # Encrypt coefficients\n",
    "\n",
    "cipher_X = encrypt_array(X_test,ctx)\n",
    "\n",
    "# Make predictions on encrypted data\n",
    "encrypted_prediction = np.array(my_lr.predict(cipher_X, ctx))\n",
    "# encrypted_prediction\n",
    "# X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VENUmpy predictions:  [0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1]\n",
      "Number of differing predictions: 0\n",
      "Percentage of differing predictions: 0.00%\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "# decrypt result\n",
    "decrypted_prediction = decrypt_array(encrypted_prediction)\n",
    "# convert with sigmoid and condition on threshold\n",
    "binary_predictions = np.where(1 / (1 + np.exp(-decrypted_prediction)) > 0.5, 1, 0)  # Apply sigmoid and threshold\n",
    "\n",
    "print(\"VENUmpy predictions: \", binary_predictions)\n",
    "# Check differences\n",
    "differences = binary_predictions != sk_lr_predictions\n",
    "print(\"Number of differing predictions:\", np.sum(differences))\n",
    "print(\"Percentage of differing predictions: {:.2f}%\".format(np.sum(differences) / len(X_test) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CathalEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
