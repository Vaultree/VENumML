{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afbdf6eb",
   "metadata": {},
   "source": [
    "## Encrypted Transformers \n",
    "\n",
    "This notebook documents the steps involved in training and using an encrypted instance of transformers. The model training is done in PyTorch, and the weights are then encrypted using VENumpy. Synthetic medical training data is generated with ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b40bf3be-b695-4e92-b5bf-4e13aaf79277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from transformers import DataCollatorForLanguageModeling, AutoTokenizer, DataCollatorWithPadding, BertTokenizerFast\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import venumpy\n",
    "import torch\n",
    "import pandas as pd\n",
    "# import math\n",
    "\n",
    "from venumMLlib.deep_learning.transformer.transformer import *\n",
    "from venumMLlib.venum_tools import *\n",
    "from venumMLlib.approx_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a38ee37-9c0b-4de3-8421-f83c91ce8d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the transformer data folder\n",
    "data_folder = \"../demos/transformer_demo/data/\"\n",
    "data = pd.read_csv(data_folder + \"chatgpt_medical_reports_rare_diseases.csv\",encoding='utf-8',index_col=False)\n",
    "\n",
    "data.columns = ['idx','condition', 'text']\n",
    "label_mapping = dict(zip(data.condition.unique(),range(data.condition.nunique())))\n",
    "data['label'] = data['condition'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "604bc321-d8e8-41ea-b02d-346f800054bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the dictionary\n",
    "reversed_label_mapping = {value: key for key, value in label_mapping.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12db59b3-27eb-4a79-a1f3-fee69e9670bc",
   "metadata": {},
   "source": [
    "## VENumpy Instance\n",
    "Set security level and precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8c6381a-925b-40ba-b4e2-a9f28e1fc6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = venumpy.SecretContext.new_with_security(128)\n",
    "ctx.precision= 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f8a0d-ff70-4e47-8cca-c725e9cebf70",
   "metadata": {},
   "source": [
    "## Load weights from pre-trained model\n",
    "\n",
    "In this step, we load the weights from the pre-trained model and then encrypt them using VENumpy and `venum_tools` `encrypt_array` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "febbf3cd-9c66-46d2-b936-3482bb8c3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../demos/transformer_demo/model/\"\n",
    "state_dict = torch.load(model_path + 'medical_2heads.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "420fc2ce-784f-43ee-bdb2-fe3668cd23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_state_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d887097a-4b06-4926-9e02-0e832d81cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "705602f3-006f-4387-b387-716d57727cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e1faf5af614e4cbb3acd366599a0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in tqdm(state_dict.keys()):\n",
    "    weight = state_dict[k].T.numpy()\n",
    "    encrypted_state_dict[k] = encrypt_array(weight,ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc4c212a-3962-4691-8866-88c34187611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = state_dict['embeddings.weight'].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223df6e0-f3ff-45ac-b354-f138bdd0ce2c",
   "metadata": {},
   "source": [
    "## Model hyper parameters\n",
    "Next, we retrieve and print the model hyperparameters to understand the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9427bd9-a0f7-45f9-84a8-8d6a196595d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 20\n",
    "d_model = 8\n",
    "num_heads = 2\n",
    "d_ff = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb75ae3-4329-4821-b2b1-6e106a200b0d",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "Load the tokenizer associated with the pre-trained model. In this case, using BERT. Prepare your synthetic medical data for tokenization based on the model's requirements. We use a tokenizer to process the synthetic medical data. This tokenizer converts text inputs into token IDs that can be fed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18cbdccb-480b-4853-8ded-1d362880885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a tokenizer (example using BERT tokenizer)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(  \"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bc9707e-2093-43c0-b331-0ee708cb4509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97ab2b03-249c-4ff8-bc4d-f40f9b5c3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_input(sentence, tokenizer, max_seq_len):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        sentence,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_seq_len,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt',\n",
    "        truncation=True\n",
    "    )\n",
    "    # Convert the tensor to a numpy array\n",
    "    input_ids_numpy = inputs['input_ids'].squeeze().numpy()\n",
    "    return input_ids_numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71e06a0c-4048-4632-82a2-bd75dc825266",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "class_size = len(reversed_label_mapping)\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e274a6",
   "metadata": {},
   "source": [
    "## Softmax \n",
    "We pass the tokenized input through the model, and then apply softmax to get the probabilities of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b5b572b-d2e5-41eb-b690-4c1ea6743dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    # Subtract the max for numerical stability\n",
    "    x_max = np.max(x, axis=-1, keepdims=True)\n",
    "    \n",
    "    # Log of the sum of exponentials of the input elements\n",
    "    log_sum_exp = np.log(np.sum(np.exp(x - x_max), axis=-1, keepdims=True))\n",
    "    \n",
    "    return x - x_max - log_sum_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f773e49-228e-4546-924f-6f6e1e691b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_batch_indices(texts, max_seq_len):\n",
    "    \"\"\"\n",
    "    Converts a batch of texts to a list of lists of indices based on a vocabulary dictionary.\n",
    "\n",
    "    Args:\n",
    "    - texts (list of str): The input texts.\n",
    "    - vocab_dict (dict): The vocabulary dictionary mapping words to indices.\n",
    "\n",
    "    Returns:\n",
    "    - list of list: List of lists of indices representing the texts.\n",
    "    \"\"\"\n",
    "    batch_indices = []\n",
    "    for text in texts:\n",
    "        indices = tokenize_input(text,tokenizer, max_seq_len)\n",
    "        batch_indices.append(indices)\n",
    "    return batch_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a38a6db",
   "metadata": {},
   "source": [
    "## Inference Text\n",
    "Create the prompt listing of symptoms used to perform the final diagnosis, then encrypt it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e855a50-cd20-4280-80fd-40f4ef64a318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liver Function Tests (LFTs): Results indicating liver dysfunction (AST, ALT, Bilirubin elevated)\n"
     ]
    }
   ],
   "source": [
    "texts = [\"Liver Function Tests (LFTs): Results indicating liver dysfunction (AST, ALT, Bilirubin elevated)\"]\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "565a84a7-732d-4b67-8efd-6e1a92843be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_indices = texts_to_batch_indices(texts, max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78be039b-8317-47cb-b10e-903cf9d8af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b31195d-e148-4407-b9d0-e2b677d224ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = Embeddings(embedding_weights)\n",
    "embedding_output = embeddings.forward(batch_indices,batch_size,max_seq_len)\n",
    "embedding_output= encrypt_array(embedding_output,ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c03f60c-aeca-4a41-8884-3d20858b30d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<venumpy.Ciphertext object at 0x33dc13990>\n",
      " <venumpy.Ciphertext object at 0x37bd54890>\n",
      " <venumpy.Ciphertext object at 0x33edac990>\n",
      " <venumpy.Ciphertext object at 0x33dc0bb10>\n",
      " <venumpy.Ciphertext object at 0x34202cbd0>\n",
      " <venumpy.Ciphertext object at 0x33a5c7a90>\n",
      " <venumpy.Ciphertext object at 0x342006790>\n",
      " <venumpy.Ciphertext object at 0x342004090>]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_output[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94982692",
   "metadata": {},
   "source": [
    "## Encrypted Transformer Class\n",
    "The encrypted weights (`encrypted_state_dict`) are passed as an argument to the Encrypted Transformer Class (`TransformerModule`) along with the hyperparameters listed previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d30a8f1-9178-4a67-a54d-3225fbc7dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransformerModule(encrypted_state_dict, max_seq_len=max_seq_len, d_model=8, num_heads=num_heads, d_ff=32, vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4176ad5a-998c-4ae9-a8aa-e5a0341c61e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_linear = transformer.forward(embedding_output, ctx, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c6e06b2-a2c6-4527-8780-2d1ea530c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = log_softmax([[i.decrypt() for i in batch] for batch in output_linear])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d6304d",
   "metadata": {},
   "source": [
    "## Decryption\n",
    "Decrypt the output of the encrypted transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e075a4c-6d61-4515-80bc-f52346e9c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = (decrypt_array(output_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705462e3",
   "metadata": {},
   "source": [
    "## Predicted Disease in Plaintext\n",
    "Finally, we print out the predicted class of the supplied list of symptoms based on the highest probability from the softmax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5b789c1-393d-496f-8b21-329e7e0e2a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilson's Disease\n"
     ]
    }
   ],
   "source": [
    "probs = log_softmax(output)\n",
    "predicted_class_idx = np.argmax(probs)\n",
    "predicted_class = reversed_label_mapping[predicted_class_idx]# for i in predicted_class_idx]\n",
    "print(predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
